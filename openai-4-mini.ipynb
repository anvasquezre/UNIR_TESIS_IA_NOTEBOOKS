{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1a4cc-3eb3-407a-8927-f7cb0cc4d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install numpy --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b508a56-2dfb-4c69-a16f-b1c6f48b9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.extraction.llm_extractor import LLMExtractor\n",
    "from src.extraction.output_parser import LLMOutputParser\n",
    "from src.extraction.extraction_template import template\n",
    "from src.extraction.extraction_responses import LLMResponse\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f335e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "results_path = \"./results/llama_multimodal/test\"\n",
    "error_log_path = f\"{results_path}/error_log.txt\"\n",
    "results_name = \"results_gpt_4_1_llama_multimodal.json\"\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968237f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapping = {\n",
    "    \"gpt-4-nano\" : \"gpt-4.1-nano-2025-04-14\",\n",
    "    \"gpt-4-mini\" : \"gpt-4o-mini-2024-07-18\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from core.settings import settings\n",
    "# from src.llms.llama import LLama3_2_11B_V\n",
    "llm = ChatOpenAI(\n",
    "    model=model_mapping[\"gpt-4-mini\"],\n",
    "    temperature=0,\n",
    "    openai_api_key=\"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\",\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "# llm_llama = LLama3_2_11B_V(temperature=1.5, top_p=0.9)\n",
    "\n",
    "output_parser = LLMOutputParser(\n",
    "    serializable=LLMResponse,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "\n",
    "llm_extractor = LLMExtractor(\n",
    "    llm=llm,\n",
    "    output_parser=output_parser,\n",
    "    extraction_template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f86da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"./data/df_concat_with_text.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d12c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df[\"data_split\"]== \"val\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd415db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df[\"data_split\"]== \"test\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "async def extract_and_save(context,question, question_id, results_path=None):\n",
    "    try:\n",
    "        saving_path = f\"{results_path}/{question_id}.json\"\n",
    "        if os.path.exists(saving_path):\n",
    "            return\n",
    "        result = await llm_extractor.aextract(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                )\n",
    "        with open(f\"{results_path}/{question_id}.json\", \"w\") as f:\n",
    "            f.write(result.model_dump_json())\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(f\"Error processing question {question_id}: {e}\\n\")\n",
    "        print(f\"Error processing question {question_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b94657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "async def process_df(df, results_path=None):\n",
    "    if not results_path:\n",
    "        raise ValueError(\"results_path must be provided\")\n",
    "    tasks_list = []\n",
    "    df = df.copy()\n",
    "    df[\"extraction\"] = None\n",
    "    df[\"extraction_error\"] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question_id = row[\"questionId\"]\n",
    "            question = row[\"question\"]\n",
    "            context = row[\"text\"]\n",
    "            tasks = asyncio.create_task(\n",
    "                extract_and_save(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    question_id=question_id,\n",
    "                    results_path=results_path\n",
    "                )\n",
    "            )\n",
    "            tasks_list.append(tasks)\n",
    "            await asyncio.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    await asyncio.gather(*tasks_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca74cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await process_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3858a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = os.listdir(results_path)\n",
    "len(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a592bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_results_from_path(results_path, name):\n",
    "    list_of_files = os.listdir(results_path)\n",
    "    list_of_results = []\n",
    "    for file in list_of_files:\n",
    "        try:\n",
    "            if not file.endswith(\".json\"):\n",
    "                continue\n",
    "            with open(f\"{results_path}/{file}\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            list_of_results.append({\n",
    "                \"questionId\": int(file.split(\".\")[0]),\n",
    "                \"answer\": data[\"answer\"],\n",
    "            }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file}: {e}\")\n",
    "            raise e\n",
    "    with open(name, \"w\") as f:\n",
    "        json.dump(list_of_results, f, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.extraction.llm_extractor import LLMExtractorMultimodal\n",
    "from src.extraction.extraction_template import create_image_only_template\n",
    "\n",
    "llm_extractor_multimodal = LLMExtractorMultimodal(\n",
    "    llm=llm,\n",
    "    output_parser=output_parser,\n",
    "    extraction_template=template,\n",
    "    image_template_func=create_image_only_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_and_save_multimodal(context,question, question_id, image_base64, results_path=None):\n",
    "    try:\n",
    "        saving_path = f\"{results_path}/{question_id}.json\"\n",
    "        if os.path.exists(saving_path):\n",
    "            return\n",
    "        result = await llm_extractor_multimodal.aextract(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    image=image_base64,\n",
    "                )\n",
    "        with open(f\"{results_path}/{question_id}.json\", \"w\") as f:\n",
    "            f.write(result.model_dump_json())\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(f\"Error processing question {question_id}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dff32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import base64\n",
    "async def process_df_multimodal(df, results_path=None):\n",
    "    tasks_list = []\n",
    "    df = df.copy()\n",
    "    df[\"extraction\"] = None\n",
    "    df[\"extraction_error\"] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question_id = row[\"questionId\"]\n",
    "            question = row[\"question\"]\n",
    "            context = row[\"text\"]\n",
    "            image_path = row[\"image_path\"]\n",
    "            saving_path = f\"{results_path}/{question_id}.json\"\n",
    "            if os.path.exists(saving_path):\n",
    "                continue\n",
    "            image = cv2.imread(image_path)\n",
    "            # encode the image as base64\n",
    "            _, buffer = cv2.imencode('.jpg', image)\n",
    "            image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            tasks = asyncio.create_task(\n",
    "                extract_and_save_multimodal(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    question_id=question_id,\n",
    "                    image_base64=image_base64,\n",
    "                    results_path=results_path\n",
    "                )\n",
    "            )\n",
    "            tasks_list.append(tasks)\n",
    "            await asyncio.sleep(0.1\n",
    "                                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {question_id}: {e}\")\n",
    "            continue\n",
    "    return await asyncio.gather(*tasks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results= await process_df_multimodal(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_and_save_only_image(question, question_id, image_base64, results_path=None):\n",
    "    try:\n",
    "        saving_path = f\"{results_path}/{question_id}.json\"\n",
    "        if os.path.exists(saving_path):\n",
    "            return\n",
    "        result = await llm_extractor_multimodal.aextract(\n",
    "                    question=question,\n",
    "                    image=image_base64,\n",
    "                )\n",
    "        with open(f\"{results_path}/{question_id}.json\", \"w\") as f:\n",
    "            f.write(result.model_dump_json())\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(f\"Error processing question {question_id}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def process_df_only_image(df, results_path=None):\n",
    "    tasks_list = []\n",
    "    df = df.copy()\n",
    "    df[\"extraction\"] = None\n",
    "    df[\"extraction_error\"] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question_id = row[\"questionId\"]\n",
    "            question = row[\"question\"]\n",
    "            image_path = row[\"image_path\"]\n",
    "            saving_path = f\"{results_path}/{question_id}.json\"\n",
    "            if os.path.exists(saving_path):\n",
    "                continue\n",
    "            image = cv2.imread(image_path)\n",
    "            # encode the image as base64\n",
    "            _, buffer = cv2.imencode('.jpg', image)\n",
    "            image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            tasks = asyncio.create_task(\n",
    "                extract_and_save_only_image(\n",
    "                    question=question,\n",
    "                    question_id=question_id,\n",
    "                    image_base64=image_base64,\n",
    "                    results_path=results_path\n",
    "                )\n",
    "            )\n",
    "            tasks_list.append(tasks)\n",
    "            await asyncio.sleep(0.1\n",
    "                                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {question_id}: {e}\")\n",
    "            continue\n",
    "    return await asyncio.gather(*tasks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e14742-d600-4d7d-b21f-5bee0aac5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_local_path_to_drive_path(path: str):\n",
    "  path = path.replace(\"./images/\",\"../images/\")\n",
    "  return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20804bcd-b742-4024-819c-425cdca1dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"image_path\"] = df[\"image_path\"].apply(transform_local_path_to_drive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3f64c-834d-4f1e-9700-2370df344521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4ecda-661b-448b-bc52-6e820cda79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[\"image_path\"] = df_test[\"image_path\"].apply(transform_local_path_to_drive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(df.iloc[0][\"image_path\"])\n",
    "            # encode the image as base64\n",
    "_, buffer = cv2.imencode('.jpg', image)\n",
    "image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "llm_extractor_multimodal.extract(\n",
    "    df.iloc[0][\"question\"],\n",
    "    df.iloc[0][\"text\"],\n",
    "    image=image_base64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa0fd1-8a1d-4fca-8b4a-e0949eaabb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_and_save_multimodal_local(context,question, question_id, image_base64, results_path=None):\n",
    "    try:\n",
    "        saving_path = f\"{results_path}/{question_id}.json\"\n",
    "        if os.path.exists(saving_path):\n",
    "            return\n",
    "        result = llm_extractor_multimodal.extract(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    image=image_base64,\n",
    "                )\n",
    "        with open(f\"{results_path}/{question_id}.json\", \"w\") as f:\n",
    "            f.write(result.model_dump_json())\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(f\"Error processing question {question_id}: {e}\\n\")\n",
    "            \n",
    "def extract_and_save_only_image_local(context,question, question_id, image_base64,results_path=None):\n",
    "    try:\n",
    "        saving_path = f\"{results_path}/{question_id}.json\"\n",
    "        if os.path.exists(saving_path):\n",
    "            return\n",
    "        result = llm_extractor_multimodal.extract(\n",
    "                    question=question,\n",
    "                    image=image_base64,\n",
    "                )\n",
    "        with open(f\"{results_path}/{question_id}.json\", \"w\") as f:\n",
    "            f.write(result.model_dump_json())\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(f\"Error processing question {question_id}: {e}\\n\")\n",
    "            \n",
    "def extract_and_save_local(context,question, question_id, image_base64=None, results_path=None):\n",
    "    try:\n",
    "        saving_path = f\"{results_path}/{question_id}.json\"\n",
    "        if os.path.exists(saving_path):\n",
    "            return\n",
    "        result =llm_extractor_multimodal.extract(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                )\n",
    "        with open(f\"{results_path}/{question_id}.json\", \"w\") as f:\n",
    "            f.write(result.model_dump_json())\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(f\"Error processing question {question_id}: {e}\\n\")\n",
    "\n",
    "\n",
    "def process_df_multimodal_local(df, results_path=None):\n",
    "    if not results_path:\n",
    "        raise ValueError(\"results_path must be provided\")\n",
    "    df = df.copy()\n",
    "    df[\"extraction\"] = None\n",
    "    df[\"extraction_error\"] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question_id = row[\"questionId\"]\n",
    "            question = row[\"question\"]\n",
    "            context = row[\"text\"]\n",
    "            image_path = row[\"image_path\"]\n",
    "            saving_path = f\"{results_path}/{question_id}.json\"\n",
    "            if os.path.exists(saving_path):\n",
    "                continue\n",
    "            image = cv2.imread(image_path)\n",
    "            # encode the image as base64\n",
    "            _, buffer = cv2.imencode('.jpg', image)\n",
    "            image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            extract_and_save_multimodal_local(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    question_id=question_id,\n",
    "                    image_base64=image_base64,\n",
    "                    results_path=results_path,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {question_id}: {e}\")\n",
    "            \n",
    "            continue\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def process_df_only_text_local(df,results_path=None):\n",
    "    if not results_path:\n",
    "        raise ValueError(\"results_path must be provided\")\n",
    "    df = df.copy()\n",
    "    df[\"extraction\"] = None\n",
    "    df[\"extraction_error\"] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question_id = row[\"questionId\"]\n",
    "            question = row[\"question\"]\n",
    "            context = row[\"text\"]\n",
    "            image_path = row[\"image_path\"]\n",
    "            saving_path = f\"{results_path}/{question_id}.json\"\n",
    "            if os.path.exists(saving_path):\n",
    "                continue\n",
    "            extract_and_save_local(\n",
    "                    context=context,\n",
    "                    question=question,\n",
    "                    question_id=question_id,\n",
    "                    image_base64=None,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {question_id}: {e}\")\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "def process_df_only_image_local(df,results_path=None):\n",
    "    if not results_path:\n",
    "        raise ValueError(\"results_path must be provided\")\n",
    "    df = df.copy()\n",
    "    df[\"extraction\"] = None\n",
    "    df[\"extraction_error\"] = None\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question_id = row[\"questionId\"]\n",
    "            question = row[\"question\"]\n",
    "            context = row[\"text\"]\n",
    "            image_path = row[\"image_path\"]\n",
    "            saving_path = f\"{results_path}/{question_id}.json\"\n",
    "            if os.path.exists(saving_path):\n",
    "                continue\n",
    "            image = cv2.imread(image_path)\n",
    "            # encode the image as base64\n",
    "            _, buffer = cv2.imencode('.jpg', image)\n",
    "            image_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            extract_and_save_only_image(\n",
    "                    question=question,\n",
    "                    question_id=question_id,\n",
    "                    image_base64=image_base64,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {question_id}: {e}\")\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c33fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results_from_path_with_errors(results_path, name):\n",
    "    list_of_files = os.listdir(results_path)\n",
    "    list_of_results = []\n",
    "    for file in list_of_files:\n",
    "        try:\n",
    "            if not file.endswith(\".json\"):\n",
    "                continue\n",
    "            with open(f\"{results_path}/{file}\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            answer = data[\"answer\"]\n",
    "            if not answer:\n",
    "                answer = data.get(\"unparsed_output\")\n",
    "            if not answer:\n",
    "                answer= \"\"\n",
    "            list_of_results.append({\n",
    "                \"questionId\": int(file.split(\".\")[0]),\n",
    "                \"answer\": answer,\n",
    "            }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file}: {e}\")\n",
    "            raise e\n",
    "    with open(name, \"w\") as f:\n",
    "        json.dump(list_of_results, f, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_experiment_async(base_name, process_df_func, df, data_type=\"test\"):\n",
    "    results_path = f\"./results/{base_name}/{data_type}\"\n",
    "    results_name = f\"results_{base_name}_{data_type}.json\"\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    results= await process_df_func(df, results_path=results_path)\n",
    "    list_of_files = os.listdir(results_path)\n",
    "    print(len(list_of_files))\n",
    "    format_results_from_path_with_errors(results_path, results_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS_ASYNC = [\n",
    "    {\n",
    "        \"base_name\": \"gpt-4-1-mini\",\n",
    "        \"process_df_func\": process_df,\n",
    "        \"df\": df_val,\n",
    "        \"data_type\": \"val\",\n",
    "    },\n",
    "    # gpt only images val\n",
    "    { \n",
    "        \"base_name\": \"gpt-4-1-mini-only-image\",\n",
    "        \"process_df_func\": process_df_only_image,\n",
    "        \"df\": df_val,\n",
    "        \"data_type\": \"val\",\n",
    "    },\n",
    "    # gpt multimodal val\n",
    "    {\n",
    "        \"base_name\": \"gpt-4-1-mini-multimodal\",\n",
    "        \"process_df_func\": process_df_multimodal,\n",
    "        \"df\": df_val,\n",
    "        \"data_type\": \"val\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await process_experiment_async(EXPERIMENTS_ASYNC[2][\"base_name\"],\n",
    "#                         EXPERIMENTS_ASYNC[2][\"process_df_func\"],\n",
    "#                         EXPERIMENTS_ASYNC[2][\"df\"].head(5),\n",
    "#                         data_type=EXPERIMENTS_ASYNC[2][\"data_type\"])\n",
    "\n",
    "for experiment in EXPERIMENTS_ASYNC:\n",
    "    print(\"--\"*20)\n",
    "    print(f\"Processing experiment: {experiment['base_name']}\")\n",
    "    print(f\"Data type: {experiment['data_type']}\")\n",
    "    print(f\"Processing function: {experiment['process_df_func'].__name__}\")\n",
    "    print(\"--\"*20)\n",
    "    await process_experiment_async(\n",
    "        experiment[\"base_name\"],\n",
    "        experiment[\"process_df_func\"],\n",
    "        experiment[\"df\"],\n",
    "        data_type=experiment[\"data_type\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123855f-6744-4705-8742-355fb5a03dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def process_experiment(base_name, process_df_func, df, data_type=\"test\"):\n",
    "    results_path = f\"./results/{base_name}/{data_type}\"\n",
    "    results_name = f\"results_{base_name}.json\"\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    process_df_func(df, results_path=results_path)\n",
    "    list_of_files = os.listdir(results_path)\n",
    "    print(len(list_of_files))\n",
    "    format_results_from_path_with_errors(results_path, results_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb43a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = [\n",
    "    {\n",
    "        \"base_name\": \"llama_finetuned_multimodal_2_test\",\n",
    "        \"process_df_func\": process_df_multimodal_local,\n",
    "        \"df\": df_test,\n",
    "        \"data_type\": \"test\",\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"llama_finetuned_text_only_2_test\",\n",
    "        \"process_df_func\": process_df_only_text_local,\n",
    "        \"df\": df_test,\n",
    "         \"data_type\": \"test\",\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"llama_finetuned_image_only_2_test\",\n",
    "        \"process_df_func\": process_df_only_image_local,\n",
    "        \"df\": df_test,\n",
    "        \"data_type\": \"test\",\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"llama_finetuned_multimodal_2_val\",\n",
    "        \"process_df_func\": process_df_multimodal_local,\n",
    "        \"df\": df_val,\n",
    "        \"data_type\": \"val\",\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"llama_finetuned_text_only_2_val\",\n",
    "        \"process_df_func\": process_df_only_text_local,\n",
    "        \"df\": df_val,\n",
    "        \"data_type\": \"val\",\n",
    "    },\n",
    "    {\n",
    "        \"base_name\": \"llama_finetuned_image_only_2_val\",\n",
    "        \"process_df_func\": process_df_only_image_local,\n",
    "        \"df\": df_val,\n",
    "        \"data_type\": \"val\",\n",
    "    },\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
